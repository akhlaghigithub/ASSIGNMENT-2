# -*- coding: utf-8 -*-
"""ASSIGNMENT 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C6auDVhT0XoeTFYQelqEMumYnaP8ckQh
"""

pip install nltk

import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.probability import FreqDist
from nltk.tokenize.treebank import TreebankWordDetokenizer

nltk.download('punkt')
nltk.download('stopwords')

# Function to calculate the length of a document in tokens
def calculate_length(text):
    tokens = word_tokenize(text)
    return len(tokens)

# Function to summarize text using frequency of words
def summarize_text(text, target_length):
    sentences = sent_tokenize(text)
    words = word_tokenize(text)
    freq_dist = FreqDist(words)
    stop_words = set(stopwords.words('english'))

    # Remove stopwords and punctuation from frequency distribution
    freq_dist = {word: freq for word, freq in freq_dist.items() if word.isalnum() and word not in stop_words}

    # Sort sentences by the sum of word frequencies
    scored_sentences = [(sum(freq_dist.get(word, 0) for word in word_tokenize(sentence)), sentence) for sentence in sentences]
    scored_sentences.sort(reverse=True)

    # Select sentences until target length is reached
    summary_sentences = []
    current_length = 0
    for score, sentence in scored_sentences:
        if current_length + len(word_tokenize(sentence)) <= target_length:
            summary_sentences.append(sentence)
            current_length += len(word_tokenize(sentence))
        else:
            break

    summary = TreebankWordDetokenizer().detokenize(summary_sentences)
    return summary

# Function to perform hierarchical summarization
def hierarchical_summarization(text, max_tokens):
    segments = []
    start = 0
    while start < len(text):
        end = start + max_tokens
        segment = text[start:end]
        summary = summarize_text(segment, max_tokens // 2)
        segments.append(summary)
        start = end

    final_summary = ' '.join(segments)
    return final_summary

# Example usage
text1 = "Your long text 1 goes here..."
text2 = "Your long text 2 goes here..."

# Step 1: Measure the length of the two documents
length1 = calculate_length(text1)
length2 = calculate_length(text2)

# Step 2: Compute the target lengths in a proportional way
total_length = length1 + length2
target_length1 = int((length1 / total_length) * 4000)
target_length2 = int((length2 / total_length) * 4000)

# Step 3-8: Summarize both texts
summary1 = hierarchical_summarization(text1, target_length1)
summary2 = hierarchical_summarization(text2, target_length2)

# Step 9: Generate the final query
final_query = summary1 + " " + summary2

# Print the final summary
print("Final Summary:")
print(final_query)